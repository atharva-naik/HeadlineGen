# -*- coding: utf-8 -*-
"""Translated+English_Headlines_Only_XLMProphetNet_seq2seq.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dVA-h7DgqYDn_YTJ7z2u9Gmj-5edKvOA
"""

!nvidia-smi

"""# Mount Drive (REQUIRED)"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""# Set up repo (REQUIRED)"""

cd drive/My Drive/HeadlineGeneration

#!mkdir models/

cd models/

!mkdir XLMProphetNet_with_translated_hindi/

cd XLMProphetNet_with_translated_hindi

#!mkdir saved_models/

"""# Install Requirements"""

!pip install emoji
!pip install datasets
!pip install transformers
!pip install sentencepiece

!pip install rouge_score

"""# Imports (REQUIRED)"""

import re
import os
import nltk
import datasets
import numpy as np
import pandas as po
from tqdm.notebook import tqdm

import torch
import torch.nn as nn
from typing import Optional
from dataclasses import dataclass, field
from torch.utils.data import Dataset, DataLoader, TensorDataset
from transformers import set_seed, TrainingArguments, Trainer, default_data_collator, AdamW, get_linear_schedule_with_warmup, Seq2SeqTrainer, Seq2SeqTrainingArguments

!cp ../preprocess.py .

import preprocess

nltk.download('punkt')

"""# Finetune

## Preprocess
"""

set_seed(69)

metric = datasets.load_metric('rouge')

pwd

"""
df_t = po.read_csv('../../raw_data/Hindi_translations_till_1041.csv')
df_t
df_a = df_t.loc[df_t['Hindi_translation']!="0"][["Text_ID", "Hindi_translation", "Headline", "Mobile_Tech_Flag"]].rename(columns={"Hindi_translation": "Text"})
df_a["Text_ID"] = df_a["Text_ID"].apply(lambda x: "hindi_article_"+x.split('_')[1])
df_a
df_t = df_t.drop(["Unnamed: 0", "Hindi_translation"], axis=1).append(df_a, ignore_index=True)
df_t.to_csv("../../raw_data/Hindi_translations_till_479_formatted.csv", index=False)
"""

pipeline = ["strip", "remove_emoji", "remove_newline", "remove_url", "remove_punctuation", "insert_newline", "lower"]
train, val, test = preprocess.process_dataset("../../raw_data/Hindi_translations_till_1041.csv", pipeline, 69, valid_size=1/8, test_size=1/8)

ls

os.makedirs('preprocessed_data/', exist_ok=True)

train.to_csv('preprocessed_data/train.csv', index=False)
val.to_csv('preprocessed_data/val.csv', index=False)
test.to_csv('preprocessed_data/test.csv', index=False)

from transformers import XLMProphetNetConfig, XLMProphetNetTokenizer, XLMProphetNetForConditionalGeneration

config = XLMProphetNetConfig.from_pretrained('microsoft/xprophetnet-large-wiki100-cased')
tokenizer = XLMProphetNetTokenizer.from_pretrained('microsoft/xprophetnet-large-wiki100-cased')
model = XLMProphetNetForConditionalGeneration.from_pretrained('microsoft/xprophetnet-large-wiki100-cased')

#decoder_start_token required for MBart

# Get the column names for input/target.
dataset_columns = ('text', 'summary')
text_column = dataset_columns[0]
summary_column = dataset_columns[1]

# Temporarily set max_target_length for training.
max_source_length = 500
max_target_length = 64
padding = "max_length"

device='cuda'

train_dataset = datasets.load_dataset('csv', data_files='preprocessed_data/train.csv')['train']
val_dataset = datasets.load_dataset('csv', data_files='preprocessed_data/val.csv')['train']
test_dataset = datasets.load_dataset('csv', data_files='preprocessed_data/test.csv')['train']

train_dataset

val_dataset

test_dataset

data = {'train': train_dataset, 'validation': val_dataset, 'test': test_dataset}

column_names = data["train"].column_names
column_names

prefix=""

def preprocess_function(examples):
    inputs = examples[text_column]
    targets = examples[summary_column]
    inputs = [prefix + inp for inp in inputs]
    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)

    # Setup the tokenizer for targets
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, padding=padding, truncation=True)

    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore
    # padding in the loss.
    if padding == "max_length":
        labels["input_ids"] = [
            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels["input_ids"]
        ]

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

train_dataset = train_dataset.map(
            preprocess_function,
            batched=True,
            num_proc=1,
            remove_columns=column_names,
            load_from_cache_file=False,
        )

eval_dataset = val_dataset.map(
            preprocess_function,
            batched=True,
            num_proc=1,
            remove_columns=column_names,
            load_from_cache_file=False,
        )

test_dataset = test_dataset.map(
            preprocess_function,
            batched=True,
            num_proc=1,
            remove_columns=column_names,
            load_from_cache_file=False,
        )

label_pad_token_id = -100 
data_collator = default_data_collator

metric_name = "rouge"
metric = datasets.load_metric(metric_name)

def postprocess_text(preds, labels):
    preds = [pred.strip() for pred in preds]
    labels = [label.strip() for label in labels]

    # rougeLSum expects newline after each sentence
    preds = ["\n".join(nltk.sent_tokenize(pred)) for pred in preds]
    labels = ["\n".join(nltk.sent_tokenize(label)) for label in labels]

    return preds, labels

def compute_metrics(eval_preds):
    preds, labels = eval_preds
    if isinstance(preds, tuple):
        preds = preds[0]
    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)
    
    # Replace -100 in the labels as we can't decode them.
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Some simple post-processing
    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)

    if metric_name == "rouge":
        result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)
        # Extract a few results from ROUGE
        result = {key: value.mid.fmeasure * 100 for key, value in result.items()}
    else:
        result = metric.compute(predictions=decoded_preds, references=decoded_labels)
        result = {"bleu": result["score"]}

    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]
    result["gen_len"] = np.mean(prediction_lens)
    result = {k: round(v, 4) for k, v in result.items()}
    return result

"""## Train"""

training_args = Seq2SeqTrainingArguments(
    output_dir='./results',          # output directory
    num_train_epochs=3,              # total # of training epochs
    per_device_train_batch_size=1,   # batch size per device during training
    per_device_eval_batch_size=1,    # batch size for evaluation
    warmup_steps=500,                # number of warmup steps for learning rate scheduler
    weight_decay=0.01,               # strength of weight decay
    logging_dir='./logs',            # directory for storing logs
    save_steps=5673,
    predict_with_generate=True
)

# Initialize our Trainer
trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

model.cuda()
'block print'

checkpoint = None 
train_result = trainer.train(resume_from_checkpoint=checkpoint)
trainer.save_model()  # Saves the tokenizer too for easy upload

train_result

test_results = trainer.predict(
      test_dataset,
      metric_key_prefix="test",
      max_length=max_target_length,
      num_beams=4
)

test_results

os.makedirs('predictions/', exist_ok=True)

if trainer.is_world_process_zero():
  if training_args.predict_with_generate:
      test_preds = tokenizer.batch_decode(
          test_results.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True
      )
      test_preds = [pred.strip() for pred in test_preds]
      output_test_preds_file = os.path.join('predictions/', "test_generations.txt")
      with open(output_test_preds_file, "w") as writer:
          writer.write("\n".join(test_preds))

trainer.save_model()

ls

preds = test_preds
df_test = pd.read_csv('preprocessed_data/test.csv')
trues = df_test['summary'].tolist()

test_dataset = datasets.load_dataset('csv', data_files='preprocessed_data/test.csv')['train']
test_dataset[:5]['summary']

test_preds[:5]

trues[:5]

preds[:5]

"""# Official Eval Metrics

## Installs and Imports
"""

!pip install -U sentence-transformers
!pip install -U rouge

import scipy
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report
from rouge import Rouge
from statistics import mean
import nltk
nltk.download('punkt')

from nltk.translate.bleu_score import sentence_bleu, corpus_bleu

"""## Mean Similarity Score (based on sentence transformer)"""

# Get average document similarity using BERT
model = SentenceTransformer('bert-base-nli-mean-tokens')

# Get a vector for each headlines
# actual_headline = 'West Bengal: BJP Holds Mega Rally In Nandigram Ahead Of JP Naddas Visit'
# predicted_headline = 'Battleground Bengal: Dilip Ghosh Holds Rally In Howrah, Says, West Bengal Has Faith In BJP'
actual_headline_embeddings = model.encode(trues)
predicted_headline_embeddings = model.encode(preds)

distance = scipy.spatial.distance.cdist(actual_headline_embeddings, predicted_headline_embeddings, "cosine")[0]
print("Mean Similarity Score: %.4f" % np.mean(1-distance))

"""## Rouge Scores"""

# Rouge Scores
rouge = Rouge()

# Headlines Actual and Predicted
# actual_headline = 'West Bengal: BJP Holds Mega Rally In Nandigram Ahead Of JP Naddas Visit'
# predicted_headline = 'Battleground Bengal: Dilip Ghosh Holds Rally In Howrah, Says, West Bengal Has Faith In BJP'

rouge_score = rouge.get_scores(trues, preds)
rouge_scores = rouge_score[0]['rouge-l']

rouge_scores

"""## BLEU Scores"""

# BLEU Scores
actual_headline = 'West Bengal: BJP Holds Mega Rally In Nandigram Ahead Of JP Naddas Visit'
predicted_headline = 'Battleground Bengal: Dilip Ghosh Holds Rally In Howrah, Says, West Bengal Has Faith In BJP'

#hypothesis = predicted_headline.split()
#reference = actual_headline.split()
#references = [reference] # list of references for 1 sentence.
#list_of_references = [references] # list of references for all sentences in corpus.
#list_of_hypotheses = [hypothesis] # list of hypotheses that corresponds to list of references.
bleu_score = corpus_bleu(trues, preds)

bleu_score

